{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import shorthand as shnd\n",
    "\n",
    "s = shnd.Shorthand(\n",
    "    entry_syntax=\"shorthand/resources/default_entry_syntax.csv\",\n",
    "    link_syntax=\"shorthand/resources/default_link_syntax.csv\",\n",
    "    syntax_case_sensitive=False\n",
    ")\n",
    "'''\n",
    "parsed = s.parse_text(\n",
    "    'shorthand/test_data/manual_annotation.shnd',\n",
    "    skiprows=2,\n",
    "    comment_char='#'\n",
    ")\n",
    "'''\n",
    "\n",
    "parsed = s.parse_text(\n",
    "    'shorthand/test_data/single_column.shnd',\n",
    "    item_separator='__',\n",
    "    default_entry_prefix='wrk',\n",
    "    space_char='|',\n",
    "    na_string_values='!',\n",
    "    na_node_type='missing',\n",
    "    skiprows=0,\n",
    "    comment_char='#',\n",
    "    drop_na=False\n",
    ")\n",
    "\n",
    "links = parsed.links\n",
    "links.iloc[60:]\n",
    "'''\n",
    "print('       strings', parsed.strings.memory_usage(deep=True).sum()/1000, 'kb')\n",
    "print('         links', parsed.links.memory_usage(deep=True).sum()/1000, 'kb')\n",
    "print('resolved links', parsed.resolve_links().memory_usage(deep=True).sum()/1000, 'kb')\n",
    "'''\n",
    "entry_type = parsed.id_lookup('link_types', 'entry')\n",
    "entry_string_ids = parsed.links.loc[parsed.links['link_type_id'] == entry_type, 'tgt_string_id']\n",
    "\n",
    "parsed.resolve_links().query('src_string.str.contains(\"nasa\")').query('src_node_type != \"shorthand_text\"').query('tgt_node_type != \"shorthand_text\"')\n",
    "\n",
    "parsed.resolve_links().query('link_type == \"cited\"').merge(parsed.links, left_index=True, right_index=True)\n",
    "\n",
    "s = parsed.synthesize_shorthand_entries('wrk', fill_spaces=True)\n",
    "\n",
    "check = pd.Series([\n",
    "    'asmith_bwu__1999__s_bams__101__803__xxx',\n",
    "    'asmith_bwu__1998__s_bams__100__42__yyy',\n",
    "    'bjones__1975__s_jats__90__1__!',\n",
    "    'bwu__1989__t_long|title__!__80__!',\n",
    "    'Some|Author__1989__t_A|Title|With|\\\\#__!__!__!',\n",
    "    'asmith_bwu__2008__s_bams__110__1__zzz'\n",
    "])\n",
    "\n",
    "(check == s).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                   638\n",
       "1                                                   641\n",
       "2                                                   311\n",
       "3                                                   323\n",
       "4                                                   261\n",
       "5                                                   280\n",
       "6                                                   451\n",
       "7                                                   453\n",
       "8                                                  1962\n",
       "9                                    Newkirk, Gordon A.\n",
       "10                                        Eddy, John A.\n",
       "11                                     Wiin-Nielsen, A.\n",
       "12                                    Lally, Vincent E.\n",
       "13                                               Nature\n",
       "14                               Monthly Weather Review\n",
       "15                                               Tellus\n",
       "16      Bulletin of the American Meteorological Society\n",
       "17                                                 4829\n",
       "18                                                    8\n",
       "19                                                    3\n",
       "20                                                    9\n",
       "21                                     10.1038/194638b0\n",
       "22      10.1175/1520-0493(1962)090<0311:OTOKEB>2.0.CO;2\n",
       "23                           10.3402/tellusa.v14i3.9551\n",
       "24                           10.1175/1520-0477-43.9.451\n",
       "25                                                  194\n",
       "26                                                   90\n",
       "27                                                   14\n",
       "28                                                   43\n",
       "29    Daytime {Sky} {Radiance} from {Forty} to {Eigh...\n",
       "30    {ON} {TRANSFORMATION} {OF} {KINETIC} {ENERGY} ...\n",
       "31    On truncation errors due to vertical differenc...\n",
       "32    Meteorological {Measurements}â€”{The} {Gentle} {...\n",
       "33                                                    !\n",
       "34    \"638--641\", \"1962\", \"Newkirk, Gordon A. and Ed...\n",
       "35    \"311--323\", \"1962\", \"Wiin-Nielsen, A.\", \"Month...\n",
       "36    \"261--280\", \"1962\", \"Wiin-Nielsen, A.\", \"Tellu...\n",
       "37    \"451--453\", \"1962\", \"Lally, Vincent E.\", \"Bull...\n",
       "38                                                    1\n",
       "39                                                    2\n",
       "Name: string, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import shorthand as shnd\n",
    "from bibtexparser.bparser import BibTexParser as _BibTexParser\n",
    "\n",
    "bibtex_parser = _BibTexParser(common_strings=True)\n",
    "with open(\"shorthand/test_data/bibtex_test_data_short.bib\", encoding='utf8') as f:\n",
    "    bibdatabase = bibtex_parser.parse_file(f)\n",
    "\n",
    "data = pd.DataFrame(bibdatabase.entries)\n",
    "\n",
    "s = shnd.Shorthand(\n",
    "    entry_syntax=\"shorthand/resources/default_bibtex_syntax.csv\",\n",
    "    syntax_case_sensitive=False\n",
    ")\n",
    "\n",
    "parsed = s.parse_items(\n",
    "    data.iloc[:4],\n",
    "    space_char='|',\n",
    "    na_string_values='!',\n",
    "    na_node_type='missing'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "    (check == synthesized).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "815b2be54127abaf32a64efea7cd3ff17cdf2bced9eda4b4c37568bb3e1c75a5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
