{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import shorthand as shnd\n",
    "\n",
    "s = shnd.Shorthand(\n",
    "    entry_syntax=\"shorthand/resources/default_entry_syntax.csv\",\n",
    "    link_syntax=\"shorthand/resources/default_link_syntax.csv\",\n",
    "    item_separator='__',\n",
    "    default_entry_prefix='wrk',\n",
    "    space_char='|',\n",
    "    na_string_values='!',\n",
    "    na_node_type='missing',\n",
    "    syntax_case_sensitive=False\n",
    ")\n",
    "'''\n",
    "parsed = s.parse_text(\n",
    "    'shorthand/test_data/manual_annotation.shnd',\n",
    "    skiprows=2,\n",
    "    comment_char='#'\n",
    ")\n",
    "'''\n",
    "parsed = s.parse_text(\n",
    "    'shorthand/test_data/single_column.shnd',\n",
    "    skiprows=0,\n",
    "    comment_char='#',\n",
    "    drop_na=False\n",
    ")\n",
    "\n",
    "links = parsed.links\n",
    "links.iloc[60:]\n",
    "'''\n",
    "print('       strings', parsed.strings.memory_usage(deep=True).sum()/1000, 'kb')\n",
    "print('         links', parsed.links.memory_usage(deep=True).sum()/1000, 'kb')\n",
    "print('resolved links', parsed.resolve_links().memory_usage(deep=True).sum()/1000, 'kb')\n",
    "'''\n",
    "entry_type = parsed.id_lookup('link_types', 'entry')\n",
    "entry_string_ids = parsed.links.loc[parsed.links['link_type_id'] == entry_type, 'tgt_string_id']\n",
    "\n",
    "parsed.resolve_links().query('src_string.str.contains(\"nasa\")').query('src_node_type != \"shorthand_text\"').query('tgt_node_type != \"shorthand_text\"')\n",
    "\n",
    "parsed.resolve_links().query('link_type == \"cited\"').merge(parsed.links, left_index=True, right_index=True)\n",
    "\n",
    "s = parsed.synthesize_entries('wrk', fill_spaces=True)\n",
    "\n",
    "check = pd.Series([\n",
    "    'asmith_bwu__1999__s_bams__101__803__xxx',\n",
    "    'asmith_bwu__1998__s_bams__100__42__yyy',\n",
    "    'bjones__1975__s_jats__90__1__!',\n",
    "    'bwu__1989__t_long|title__!__80__!',\n",
    "    'Some|Author__1989__t_A|Title|With|\\\\#__!__!__!',\n",
    "    'asmith_bwu__2008__s_bams__110__1__zzz'\n",
    "])\n",
    "\n",
    "(check == s).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1\n",
       "0  1  a\n",
       "1  2  b\n",
       "2  3  c"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([pd.Series([1,2,3]), pd.Series(['a','b','c'])], axis='columns', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m/\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "Return a copy with all occurrences of substring old replaced by new.\n",
      "\n",
      "  count\n",
      "    Maximum number of occurrences to replace.\n",
      "    -1 (the default value) means replace all occurrences.\n",
      "\n",
      "If the optional argument count is given, only the first count occurrences are\n",
      "replaced.\n",
      "\u001b[1;31mType:\u001b[0m      method_descriptor\n"
     ]
    }
   ],
   "source": [
    "pd.Series(['_____', '__ ', 'a']).str.replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_entry</th>\n",
       "      <th>right_entry</th>\n",
       "      <th>link_tags_or_override</th>\n",
       "      <th>reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asmith_bwu__1999__bams__101__803__xxx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>asmith_bwu__1998__bams__100__42__yyy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bjones__1975__jats__90__1__ bjones1975_is_tagg...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bwu__1989__t_long|title__!__80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Some Author__1989__t_A Title With \\#__!__!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>asmith_bwu__2008__bams__110__1__zzz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          left_entry   right_entry  \\\n",
       "0              asmith_bwu__1999__bams__101__803__xxx           NaN   \n",
       "1               asmith_bwu__1998__bams__100__42__yyy           NaN   \n",
       "2  bjones__1975__jats__90__1__ bjones1975_is_tagg...           NaN   \n",
       "3                     bwu__1989__t_long|title__!__80           NaN   \n",
       "4         Some Author__1989__t_A Title With \\#__!__!           NaN   \n",
       "5                asmith_bwu__2008__bams__110__1__zzz           NaN   \n",
       "\n",
       "    link_tags_or_override   reference  \n",
       "0                     NaN         NaN  \n",
       "1                     NaN         NaN  \n",
       "2                     NaN         NaN  \n",
       "3                     NaN         NaN  \n",
       "4                     NaN         NaN  \n",
       "5                     NaN         NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('shorthand/test_data/single_column.shnd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left entry</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  left entry  Unnamed: 1\n",
       "0          a         NaN\n",
       "1          b         NaN\n",
       "2          c         NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import StringIO\n",
    "import pandas as pd\n",
    "\n",
    "with StringIO('left entry,\\na,\\nb,\\nc,') as stream:\n",
    "    a = pd.read_csv(stream)\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Make a function that reads a csv file representing entries into\n",
    "ParsedShorthand. Column labels are missing or numeric; entry syntax is\n",
    "defined positionally as if each line were an entry string in the manual\n",
    "scheme.\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "import shorthand as shnd\n",
    "\n",
    "na_string_values = []\n",
    "na_node_type = 'missing'\n",
    "entry_node_type = 'entry_node_type'\n",
    "entry_syntax = ''\n",
    "space_char = '|'\n",
    "big_id_dtype = pd.Int32Dtype()\n",
    "small_id_dtype = pd.Int8Dtype()\n",
    "\n",
    "data = pd.DataFrame(columns=['item', 'labels'])\n",
    "\n",
    "entries = data.apply(lambda x: ', '.join(map(str, x)), axis=1)\n",
    "entries = pd.DataFrame({'string': entries.array, 'node_type': entry_node_type})\n",
    "entries = entries.reset_index().rename(columns={'index': 'csv_row'})\n",
    "\n",
    "# Replace NA values and empty strings with the first string in\n",
    "# na_string_values\n",
    "data = data.fillna(na_string_values[0])\n",
    "data = data.replace('', na_string_values[0])\n",
    "\n",
    "# items with no node type in the entry syntax are prefixed to\n",
    "# indicate which node type they correspond to\n",
    "item_is_prefixed = entry_syntax['item_node_type'].isna()\n",
    "\n",
    "if item_is_prefixed.any():\n",
    "\n",
    "    prefixed_items = entry_syntax.loc[item_is_prefixed]\n",
    "    labels_of_prefixed_items = prefixed_items['item_label'].array\n",
    "\n",
    "    # stack the prefixed items into a series\n",
    "    disagged = data[labels_of_prefixed_items].stack()\n",
    "\n",
    "    # Split the prefixes off of the stacked items and expand into a\n",
    "    # dataframe\n",
    "    disagged = disagged.groupby(level=1).apply(\n",
    "        shnd.entry_parsing._item_prefix_splitter,\n",
    "        prefixed_items\n",
    "    )\n",
    "\n",
    "    # drop the item labels from the multiindex so the disaggregated\n",
    "    # items align with the index of the entry group\n",
    "    disagged.index = disagged.index.droplevel(1)\n",
    "\n",
    "    # pivot the disaggregated items to create a dataframe with\n",
    "    # columns for each item prefix\n",
    "    disagged = disagged.pivot(columns=0)\n",
    "    disagged.columns = disagged.columns.get_level_values(1)\n",
    "\n",
    "    # get labels of items that are not prefixed and present in this\n",
    "    # dataset\n",
    "    unprefixed_item_labels = [\n",
    "        label for label in entry_syntax['item_label']\n",
    "        if label.isdigit()\n",
    "        and label in data.columns\n",
    "        and label not in labels_of_prefixed_items\n",
    "    ]\n",
    "\n",
    "    # select only the unprefixed item labels\n",
    "    data = data[unprefixed_item_labels]\n",
    "    # concatenate the unprefixed and prefixed items\n",
    "    data = pd.concat([data, disagged], axis='columns')\n",
    "\n",
    "# Replace any empty strings with null values\n",
    "data = data.mask(data == '', pd.NA)\n",
    "\n",
    "# Regular expressions to match bare and escaped space placeholders\n",
    "regex_space_char = shnd.util.escape_regex_metachars(space_char)\n",
    "space_plchldr_regex = r\"(?<!\\\\)({})\".format(regex_space_char)\n",
    "escaped_space_plchldr_regex = fr\"(\\\\{regex_space_char})\"\n",
    "\n",
    "# Replace space placeholders with spaces in the data items\n",
    "data = data.replace(\n",
    "    to_replace=space_plchldr_regex,\n",
    "    value=' ',\n",
    "    regex=True\n",
    ")\n",
    "# Replace escaped space placeholders with bare placeholders\n",
    "data = data.replace(\n",
    "    to_replace=escaped_space_plchldr_regex,\n",
    "    value=regex_space_char,\n",
    "    regex=True\n",
    ")\n",
    "\n",
    "# Stack data. Stacking creates a series whose values are the string\n",
    "# values of every item in the input and whose index levels are\n",
    "#       input index, item label\n",
    "data = data.stack()\n",
    "\n",
    "# create a map from item labels to node types and link types\n",
    "item_types = pd.DataFrame(\n",
    "    {\n",
    "        'node_type': entry_syntax['item_node_type'].array,\n",
    "        'link_type': entry_syntax['item_link_type'].array\n",
    "    },\n",
    "    index=entry_syntax['item_label'].array\n",
    ")\n",
    "item_types = item_types.loc[data.index.get_level_values(1)]\n",
    "\n",
    "data = pd.concat([data.rename('string'), item_types], axis=1)\n",
    "# data = _set_StringDtype(data)\n",
    "\n",
    "data = data.reset_index()\n",
    "data = data.rename(\n",
    "    columns={\n",
    "        'level_0': 'csv_row',\n",
    "        'level_1': 'item_label'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Concatenate expanded items with the entries\n",
    "data = pd.concat([data, entries]).sort_index().fillna(pd.NA)\n",
    "\n",
    "# For any strings that represent null values, overwrite the node\n",
    "# type inferred from the syntax with the null node type\n",
    "null_strings = data['string'].isin(na_string_values)\n",
    "data.loc[null_strings, 'node_type'] = na_node_type\n",
    "\n",
    "dtypes = {\n",
    "    'csv_row': big_id_dtype,\n",
    "    # 'item_label': pd.StringDtype(),\n",
    "    # 'string': pd.StringDtype(),\n",
    "    # 'node_type': pd.StringDtype(),\n",
    "    # 'link_type': pd.StringDtype()\n",
    "}\n",
    "# can't use pd.StringDtype() throughout because it currently\n",
    "# doesn't allow construction with null types other than pd.NA.\n",
    "# This will likely change soon\n",
    "# https://github.com/pandas-dev/pandas/pull/41412\n",
    "\n",
    "data = data.astype(dtypes)\n",
    "data.index = data.index.astype(big_id_dtype)\n",
    "\n",
    "'''\n",
    "data is currently a DataFrame with these columns:\n",
    "    ['csv_row', 'item_label', 'string', 'node_type', 'link_type']\n",
    "csv_row is integer-valued, others are 'object'\n",
    "'''\n",
    "\n",
    "# Map string-valued item labels to integer IDs\n",
    "item_label_id_map = shnd.Shorthand._create_id_map(\n",
    "    data['item_label'],\n",
    "    dtype=small_id_dtype\n",
    ")\n",
    "# Replace item labels in the mutable data with integer IDs\n",
    "data['item_label'] = data['item_label'].map(\n",
    "    item_label_id_map\n",
    ")\n",
    "data = data.rename(\n",
    "    columns={'item_label': 'item_label_id'}\n",
    ")\n",
    "\n",
    "# These link types are required to complete linking operations\n",
    "# later\n",
    "link_types = pd.Series(['entry', 'tagged', 'requires'])\n",
    "\n",
    "# Map string-valued link types to integer IDs\n",
    "link_types = shnd.Shorthand._create_id_map(\n",
    "    pd.concat([link_types, data['link_type']]),\n",
    "    dtype=small_id_dtype\n",
    ")\n",
    "# Replace link types in the mutable data with integer IDs\n",
    "data['link_type'] = data['link_type'].map(\n",
    "    link_types\n",
    ")\n",
    "data = data.rename(\n",
    "    columns={'link_type': 'link_type_id'}\n",
    ")\n",
    "# Mutate link_types into a series whose index is integer IDs and\n",
    "# whose values are string-valued link types\n",
    "link_types = pd.Series(link_types.index, index=link_types)\n",
    "\n",
    "'''\n",
    "NEXT\n",
    "    expand items that have list delimiters in the syntax\n",
    "    (line 969 in Shorthand.py)\n",
    "\n",
    "    get the list positions (lines 975-1006 in Shorthand.py)\n",
    "\n",
    "    create node types and map them in data\n",
    "    (lines 1036-1047 + line 1060 in Shorthand.py)\n",
    "\n",
    "    make the strings table, convert 'string' to 'string_id'\n",
    "    drop node_type_id from data\n",
    "\n",
    "    make links (lines 1070-1130 + line 1354 in Shorthand.py)\n",
    "\n",
    "    decide what to do with tags\n",
    "\n",
    "    make an item_label_id_map\n",
    "\n",
    "    return ParsedShorthand\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>a</th>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>b</th>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>NaN</th>\n",
       "      <td>30</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>NaN</th>\n",
       "      <td>40</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1\n",
       "1 a    10  100\n",
       "2 b    20  200\n",
       "1 NaN  30  300\n",
       "2 NaN  40  400"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mi = pd.MultiIndex.from_arrays(((1,2), ('a','b')))\n",
    "df = pd.DataFrame([[10,100],[20,200]], index=mi)\n",
    "\n",
    "mi = pd.MultiIndex.from_arrays(((1,2), (pd.NA, pd.NA)))\n",
    "df2 = pd.DataFrame([[30,300],[40,400]], index=mi)\n",
    "\n",
    "pd.concat([df, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "815b2be54127abaf32a64efea7cd3ff17cdf2bced9eda4b4c37568bb3e1c75a5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
